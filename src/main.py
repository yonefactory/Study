import requests
from bs4 import BeautifulSoup
import openai
import spacy
import time
from telegram_bot import send_telegram_message
from config import OPENAI_API_KEY, NEWS_URL

nlp = spacy.load("en_core_web_sm")

client = openai.OpenAI(api_key=OPENAI_API_KEY)

def request_with_retry(prompt, model="gpt-3.5-turbo", retries=5, delay=10):
    """OpenAI API ìš”ì²­ ì‹œ Rate Limit ì˜¤ë¥˜ ë°œìƒ ì‹œ ìë™ ì¬ì‹œë„"""
    for i in range(retries):
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "system", "content": prompt}]
            )
            return response.choices[0].message.content.strip()
        except openai.RateLimitError:
            print(f"âš ï¸ API ìš”ì²­ ì œí•œ. {delay}ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„ ({i+1}/{retries})...")
            time.sleep(delay)  
    raise Exception("ğŸš¨ API ìš”ì²­ ì‹¤íŒ¨: Rate Limit ì´ˆê³¼")

def get_latest_news():
    """ìµœì‹  ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    try:
        response = requests.get(NEWS_URL)
        response.raise_for_status()
    except requests.RequestException as e:
        print(f"ğŸš¨ ë‰´ìŠ¤ í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨: {e}")
        return None, None, None

    soup = BeautifulSoup(response.text, "html.parser")
    article = soup.find("a", class_="container__link")
    if not article:
        return None, None, None

    article_url = "https://edition.cnn.com" + article["href"]
    try:
        article_response = requests.get(article_url)
        article_response.raise_for_status()
    except requests.RequestException:
        return None, None, None

    article_soup = BeautifulSoup(article_response.text, "html.parser")
    paragraphs = article_soup.find_all("p")

    title = article_soup.find("h1").text if article_soup.find("h1") else None
    content = " ".join([p.text for p in paragraphs[:5]]) if paragraphs else None
    return title, content, article_url

def translate_text(text, target_language="ko"):
    """GPTë¥¼ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ ë²ˆì—­"""
    if not text:
        return "ë²ˆì—­í•  ë‚´ìš© ì—†ìŒ"
    prompt = f"Translate the following text to {target_language}:\n\n{text}"
    return request_with_retry(prompt, model="gpt-3.5-turbo")

def extract_keywords(sentence):
    """í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ìµœëŒ€ 5ê°œ)"""
    if not sentence:
        return []
    doc = nlp(sentence)
    keywords = [token.text for token in doc if token.pos_ in ["NOUN", "VERB", "ADJ"] and len(token.text) > 3]
    return keywords[:5]  # ìµœëŒ€ 5ê°œê¹Œì§€ ì„ íƒ

def generate_conversation(phrase):
    """GPTë¥¼ í™œìš©í•´ í•´ë‹¹ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ì§§ì€ ëŒ€í™” ì˜ˆì œ ìƒì„±"""
    prompt = f"Create a short dialogue using the phrase '{phrase}'."
    return request_with_retry(prompt, model="gpt-3.5-turbo")

def fetch_valid_news_data(max_retries=3):
    """ìµœì†Œí•œ 2ê°œì˜ ìœ íš¨í•œ í‚¤ì›Œë“œë¥¼ í™•ë³´í•  ë•Œê¹Œì§€ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    for attempt in range(max_retries):
        news_title, news_content, news_url = get_latest_news()
        if not news_title or not news_content:
            print(f"âš ï¸ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨. {attempt+1}/{max_retries}ë²ˆì§¸ ì¬ì‹œë„...")
            continue

        summary_sentence = request_with_retry(f"Summarize this in one sentence:\n{news_content}")
        summary_sentence_ko = translate_text(summary_sentence, target_language="ko")

        keywords = extract_keywords(summary_sentence)

        if len(keywords) >= 2:
            return news_title, news_url, summary_sentence, summary_sentence_ko, keywords

        print(f"âš ï¸ ìœ íš¨í•œ í‚¤ì›Œë“œ ë¶€ì¡±. {attempt+1}/{max_retries}ë²ˆì§¸ ì¬ì‹œë„...")

    return "No News Available", None, "No Summary Available", "ìš”ì•½í•  ë‰´ìŠ¤ ì—†ìŒ", []

# ì‹¤í–‰
news_title, news_url, summary_sentence, summary_sentence_ko, keywords = fetch_valid_news_data()

if len(keywords) < 2:
    send_telegram_message("âš ï¸ ì˜¤ëŠ˜ì€ ì ì ˆí•œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‚´ì¼ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.")
    exit()

keyword_text = "\n".join([f"- {kw} ({translate_text(kw)})" for kw in keywords])

conversations = []
for kw in keywords:
    conv_en = generate_conversation(kw)
    conv_ko = translate_text(conv_en)
    conversations.append(f"{conv_en}\nğŸ“Œ {conv_ko}\n")

full_message = (
    "ğŸ“š *ì˜¤ëŠ˜ì˜ ì˜ì–´ í•™ìŠµ*\n\n"
    "ğŸ“° *ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ í—¤ë“œë¼ì¸:*\n"
    + news_title + "\n"
    "ğŸ“Œ " + translate_text(news_title) + "\n"
    "ğŸ”— " + (news_url if news_url else "ë§í¬ ì—†ìŒ") + "\n\n"
    "ğŸ’¡ *ì˜¤ëŠ˜ì˜ í•µì‹¬ ë¬¸ì¥:*\n" 
    + summary_sentence + "\n"
    "ğŸ“Œ " + summary_sentence_ko + "\n\n"
    "ğŸ” *ì˜¤ëŠ˜ì˜ í‚¤ì›Œë“œ*\n"
    + keyword_text + "\n\n"
    "---\n\n"
    "ğŸŒ… *ì˜¤ì „ í•™ìŠµ*\n"
    "ì˜¤ëŠ˜ì€ ì´ í‚¤ì›Œë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì˜ì–´ë¥¼ ì—°ìŠµí•´ë³¼ ê±°ì˜ˆìš”! ì‹¤ìƒí™œì—ì„œ ì–´ë–»ê²Œ í™œìš©ë˜ëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”. ğŸ˜Š\n\n"
    "ğŸ’¬ *ëŒ€í™” ì†ì—ì„œ ë°°ìš°ê¸°*\n"
    + conversations[0] + "\n"
    "---\n\n"
    "ğŸŒ‡ *ì˜¤í›„ í•™ìŠµ*\n"
    "í•˜ë£¨ ë™ì•ˆ ë°°ìš´ ë‚´ìš©ì„ ë‹¤ì‹œ í•œ ë²ˆ ë³µìŠµí•´ë³´ì„¸ìš”! ë‹¤ë¥¸ ë§¥ë½ì—ì„œ ê°™ì€ í‘œí˜„ì„ ì“°ë©´ ê¸°ì–µì— ë” ì˜ ë‚¨ì•„ìš”. ğŸ“š\n\n"
    "ğŸ’¬ *ëŒ€í™” ì†ì—ì„œ ë°°ìš°ê¸°*\n"
    + conversations[1] + "\n"
    "---\n\n"
    "ğŸŒ™ *ì €ë… ë³µìŠµ ì‹œê°„*\n"
    "ğŸ“– ì˜¤ëŠ˜ ë°°ìš´ ë‚´ìš©ì„ í•œëˆˆì— ì •ë¦¬í•´ë³´ì„¸ìš”!\n\n"
    "ğŸ“° *í—¤ë“œë¼ì¸:* " + news_title + "\n"
    "ğŸ“Œ " + translate_text(news_title) + "\n\n"
    "ğŸ’¡ *í•µì‹¬ ë¬¸ì¥:* " + summary_sentence + "\n"
    "ğŸ“Œ " + summary_sentence_ko + "\n\n"
    "ğŸ” *ì˜¤ëŠ˜ì˜ í‚¤ì›Œë“œ*\n"
    + keyword_text + "\n\n"
    "ğŸ’¬ *ëŒ€í™” ë‹¤ì‹œ ë³´ê¸°*\n"
    + "\n".join(conversations) + "\n\n"
    "âœï¸ ì˜¤ëŠ˜ ë°°ìš´ í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•´ì„œ ì§ì ‘ ë¬¸ì¥ì„ ë§Œë“¤ì–´ ë³´ì„¸ìš”!\n"
    "ğŸ’­ ë‚´ì¼ ì•„ì¹¨ì— ë‹¤ì‹œ í™•ì¸í•˜ë©´ì„œ ë³µìŠµí•´ ë³´ì„¸ìš”!"
)

send_telegram_message(full_message)
