import requests
from bs4 import BeautifulSoup
import openai
import spacy
import time
from telegram_bot import send_telegram_message
from config import OPENAI_API_KEY, NEWS_URL

nlp = spacy.load("en_core_web_sm")

client = openai.OpenAI(api_key=OPENAI_API_KEY)

def request_with_retry(prompt, model="gpt-3.5-turbo", retries=5, delay=10):
    """OpenAI API ìš”ì²­ ì‹œ Rate Limit ì˜¤ë¥˜ ë°œìƒ ì‹œ ìë™ ì¬ì‹œë„"""
    for i in range(retries):
        try:
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "system", "content": prompt}]
            )
            return response.choices[0].message.content.strip()
        except openai.RateLimitError:
            print(f"âš ï¸ API ìš”ì²­ ì œí•œ. {delay}ì´ˆ í›„ ë‹¤ì‹œ ì‹œë„ ({i+1}/{retries})...")
            time.sleep(delay)  
    raise Exception("ğŸš¨ API ìš”ì²­ ì‹¤íŒ¨: Rate Limit ì´ˆê³¼")

def get_latest_news():
    """ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    try:
        response = requests.get(NEWS_URL)
        response.raise_for_status()
    except requests.RequestException as e:
        print(f"ğŸš¨ ë‰´ìŠ¤ í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨: {e}")
        return "No News Available", "Failed to fetch news."

    soup = BeautifulSoup(response.text, "html.parser")
    article = soup.find("a", class_="container__link")
    if not article:
        return "No News Available", "Failed to fetch news."

    article_url = "https://edition.cnn.com" + article["href"]
    try:
        article_response = requests.get(article_url)
        article_response.raise_for_status()
    except requests.RequestException:
        return "No News Available", "Failed to fetch article content."

    article_soup = BeautifulSoup(article_response.text, "html.parser")
    paragraphs = article_soup.find_all("p")

    title = article_soup.find("h1").text if article_soup.find("h1") else "No Title Found"
    content = " ".join([p.text for p in paragraphs[:5]]) if paragraphs else "No Content Found"
    return title, content

def extract_keywords(sentence):
    """í•µì‹¬ ë¬¸ì¥ì—ì„œ ë‹¨ì–´ ì¶”ì¶œ"""
    doc = nlp(sentence)
    keywords = [token.text for token in doc if token.pos_ in ["NOUN", "VERB", "ADJ"] and len(token.text) > 3]
    return keywords[:3]

def generate_expressions():
    """GPTë¥¼ ì‚¬ìš©í•´ í‘œí˜„(ìˆ™ì–´, ê´€ìš©ì–´) ìƒì„±"""
    prompt = "Generate three commonly used English expressions, including idioms or phrasal verbs."
    return request_with_retry(prompt, model="gpt-3.5-turbo").split("\n")

def generate_example_sentence(phrase):
    """GPTë¥¼ í™œìš©í•´ í•´ë‹¹ í‘œí˜„ì´ í¬í•¨ëœ ì˜ˆë¬¸ ìƒì„±"""
    prompt = f"Create a short example sentence using the phrase '{phrase}'."
    return request_with_retry(prompt, model="gpt-3.5-turbo")

def generate_conversation(phrase):
    """GPTë¥¼ í™œìš©í•´ í•´ë‹¹ í‘œí˜„ì„ í¬í•¨í•œ ì§§ì€ ëŒ€í™” ì˜ˆì œ ìƒì„±"""
    prompt = f"Create a short dialogue using the phrase '{phrase}'."
    return request_with_retry(prompt, model="gpt-3.5-turbo")

# ì‹¤í–‰
news_title, news_content = get_latest_news()
summary_sentence = request_with_retry(f"Summarize this in one sentence:\n{news_content}")
summary_sentence_ko = translate_text(summary_sentence, target_language="ko")

# í•µì‹¬ ë¬¸ì¥ì—ì„œ ë‹¨ì–´ ì¶”ì¶œ
important_terms = extract_keywords(summary_sentence)

# GPTê°€ í‘œí˜„(ìˆ™ì–´, ê´€ìš©ì–´) ìƒì„±
expressions = generate_expressions()

# ì˜ˆì™¸ ì²˜ë¦¬: ìµœì†Œí•œ ë‹¨ì–´ 1ê°œ, í‘œí˜„ 1ê°œì”© ë³´ì¥
if not important_terms:
    important_terms = ["innovation", "sustainability", "economic growth"]
if not expressions:
    expressions = ["bite the bullet", "jump on the bandwagon", "go the extra mile"]

# ì•„ì¹¨ í•™ìŠµ (ë‹¨ì–´), ì˜¤í›„ í•™ìŠµ (í‘œí˜„)ìœ¼ë¡œ ë¶„ë¦¬
selected_morning_word = important_terms[0]
selected_afternoon_expression = expressions[0]

# ì˜ˆë¬¸ ë° ëŒ€í™” ìƒì„±
morning_example_sentence = generate_example_sentence(selected_morning_word)
afternoon_conversation = generate_conversation(selected_afternoon_expression)

# Telegram ë©”ì‹œì§€ ì „ì†¡
full_message = (
    "ğŸ“š *ì˜¤ëŠ˜ì˜ ì˜ì–´ í•™ìŠµ*\n\n"
    "ğŸ“° *ì˜¤ëŠ˜ì˜ ë‰´ìŠ¤ í—¤ë“œë¼ì¸:*\n"
    + news_title + "\nğŸ“Œ " + translate_text(news_title, target_language="ko") + "\n\n"
    "ğŸ’¡ *ì˜¤ëŠ˜ì˜ í•µì‹¬ ë¬¸ì¥:* " + summary_sentence + "\nğŸ“Œ " + summary_sentence_ko + "\n\n"
    "ğŸ” *ì˜¤ëŠ˜ì˜ ë‹¨ì–´ ë° í‘œí˜„:*\n"
    "- *ë‹¨ì–´:* " + selected_morning_word + "\n"
    "- *í‘œí˜„:* " + selected_afternoon_expression + "\n\n"
    "---\n\n"
    "ğŸŒ… *ì•„ì¹¨ í•™ìŠµ (ë‹¨ì–´):* " + selected_morning_word + "\n"
    "ğŸ’¡ *ì˜ˆë¬¸:* " + morning_example_sentence + "\n"
    "âœï¸ **ì´ ë¬¸ì¥ì„ í•´ì„í•´ë³´ì„¸ìš”!**\n\n"
    "---\n\n"
    "ğŸŒ‡ *ì˜¤í›„ í•™ìŠµ (í‘œí˜„):* " + selected_afternoon_expression + "\n"
    "ğŸ’¬ *ëŒ€í™” ì†ì—ì„œ ë°°ìš°ê¸°:*\n" + afternoon_conversation + "\n\n"
    "---\n\n"
    "ğŸŒ™ *ì €ë… ë³µìŠµ ì‹œê°„*\n"
    "ğŸ“– *ì˜¤ëŠ˜ ë°°ìš´ ë‹¨ì–´ ë° í‘œí˜„:*\n"
    "- " + selected_morning_word + "\n"
    "- " + selected_afternoon_expression + "\n"
    "âœ… *ì˜¤ëŠ˜ ë°°ìš´ í‘œí˜„ì„ í™œìš©í•˜ì—¬ ë¬¸ì¥ì„ ë§Œë“¤ì–´ ë³´ì„¸ìš”!*"
)

send_telegram_message(full_message)
